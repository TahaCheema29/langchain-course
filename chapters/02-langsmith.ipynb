{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixSi6udtrYZk"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/langchain-course/blob/main/chapters/02-langsmith.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NwdBTO0qCQi"
      },
      "source": [
        "#### LangChain Essentials Course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swum099VqCQj"
      },
      "source": [
        "# LangSmith Starter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hk437ZjqCQj"
      },
      "source": [
        "LangSmith is a built-in observability service and platform that integrates _very easily_ with LangChain. You don't _need_ to use LangSmith for this course, but it can be very helpful in understanding what is happening, _and_ we recommend using it beyond this course for general development with LangChain — with all of that in mind we would recommend spending a little bit of time to get familiar with LangSmith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k9EfPofqG3g",
        "outputId": "71873d67-b511-40b8-9524-d1b0e0ddd3e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langsmith in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (0.3.4)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from pydantic<3,>=1->langsmith) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from requests<3,>=2->langsmith) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
            "Installing collected packages: langsmith\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.4\n",
            "    Uninstalling langsmith-0.3.4:\n",
            "      Successfully uninstalled langsmith-0.3.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.3.16 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.4 which is incompatible.\n",
            "langchain 0.3.17 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.4 which is incompatible.\n",
            "langchain-core 0.3.33 requires langsmith<0.4,>=0.1.125, but you have langsmith 0.4.4 which is incompatible.\n",
            "langchain-ollama 0.3.3 requires langchain-core<1.0.0,>=0.3.60, but you have langchain-core 0.3.33 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langsmith-0.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langsmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "> ⚠️ We will be using OpenAI for this example allowing us to run everything via API. If you would like to use Ollama instead, check out the [Ollama LangChain Course](https://github.com/aurelio-labs/langchain-course/tree/main/notebooks/ollama).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UdyCjmqqCQk"
      },
      "source": [
        "## Setting up LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqURpTWbqCQk"
      },
      "source": [
        "LangSmith does require an API key, but it comes with a generous free tier. You can sign up an account and get your API key [here](https://smith.langchain.com).\n",
        "\n",
        "When using LangSmith, we need to setup our environment variables _and_ provide our API key, like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezoLeIGrqCQk",
        "outputId": "252aa252-d8c3-4cd5-fb18-acf3cad2dee5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# must enter API key\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or \\\n",
        "    getpass(\"Enter LangSmith API Key: \")\n",
        "\n",
        "# below should not be changed\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "# you can change this as preferred\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"aurelioai-langchain-course-langsmith-openai\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuGDntgWqCQk"
      },
      "source": [
        "In most cases, this is all we need to start seeing logs and traces in the [LangSmith UI](https://smith.langchain.com). By default, LangChain will trace LLM calls, chains, etc. We'll take a look at a quick example of this below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDeEk0tqCQk"
      },
      "source": [
        "## Default Tracing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii3hqGO2qCQk"
      },
      "source": [
        "As mentioned, LangSmith traces a lot of data without us needing to do anything. Let's see how that looks. We'll start by initializing our LLM. Again, this will need an [API key](https://platform.openai.com/api-keys)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AfToUsEqCQl",
        "outputId": "4426952f-af46-440d-d275-a86610a9c1fe"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "llm = ChatOllama(\n",
        "    model=\"llama3.1:8b\",\n",
        "    temperature=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAVDqCttqCQl"
      },
      "source": [
        "Let's invoke our LLM and then see what happens in the LangSmith UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCGtll-IqCQl",
        "outputId": "0f9ea347-b50f-481c-c237-fd1fd6a09589"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How are you today? Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-07-06T19:56:55.746748Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11432372021, 'load_duration': 2634314021, 'prompt_eval_count': 11, 'prompt_eval_duration': 1852045310, 'eval_count': 23, 'eval_duration': 6943625915, 'model_name': 'llama3.1:8b'}, id='run--1319e462-e6c8-44e7-9a4c-a6f4213b9dde-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYM-pIIaqCQl"
      },
      "source": [
        "After this we should see that a new project (`aurelioai-langchain-course-langsmith-openai`) has been created in the LangSmith UI. Inside that project, we should see the trace from our LLM call:\n",
        "\n",
        "\n",
        "![LangSmith LLM Trace](https://github.com/aurelio-labs/langchain-course/blob/main/assets/langsmith-ui-01.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7VktC46qCQl"
      },
      "source": [
        "By default, LangSmith will capture plenty — however, it won't capture functions from outside of LangChain. Let's see how we can trace those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNQRKbp9qCQl"
      },
      "source": [
        "## Tracing Non-LangChain Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbYn3yY7qCQl"
      },
      "source": [
        "LangSmith can trace functions that are not part of LangChain, we just need to add the `@traceable` decorator. Let's try this for a few simple functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NVo50uq6qCQl"
      },
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "@traceable\n",
        "def generate_random_number():\n",
        "    return random.randint(0, 100)\n",
        "\n",
        "@traceable\n",
        "def generate_string_delay(input_str: str):\n",
        "    number = random.randint(1, 5)\n",
        "    time.sleep(number)\n",
        "    return f\"{input_str} ({number})\"\n",
        "\n",
        "@traceable\n",
        "def random_error():\n",
        "    number = random.randint(0, 1)\n",
        "    if number == 0:\n",
        "        raise ValueError(\"Random error\")\n",
        "    else:\n",
        "        return \"No error\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx4b1yJtqCQl"
      },
      "source": [
        "Let's run these a few times and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2af699bd631846bdb2e064981a48ae67",
            "1507edeb2bcf43238ed2431731b51f24",
            "76c4884af2ed4474a07a6f8964cd7b10",
            "302271efa18349fb8fd20e2fa922f17f",
            "59d44325b22241a0828dd1df4c87eb46",
            "fb6ca9c9ad144bc3947e454cc3f3ab77",
            "1e91ab27a61c4530ac1dd2e05a4455ae",
            "a087fea20eb040469312b40081517d67",
            "ba1df7e62b114c6d9062c65a04bb349d",
            "e7967f66202744d1b41ec3ae02a45617",
            "fe1edcf8e1fa4ae2bdae23d2235395e0"
          ]
        },
        "id": "iTDAR7b4qCQl",
        "outputId": "084ca65c-2497-41cf-e6f6-5b946163b5f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/taha/HDD Space/langchain-course/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "100%|██████████| 10/10 [00:33<00:00,  3.31s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "for _ in tqdm(range(10)):\n",
        "    generate_random_number()\n",
        "    generate_string_delay(\"Hello\")\n",
        "    try:\n",
        "        random_error()\n",
        "    except ValueError:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCoeNfRiqCQl"
      },
      "source": [
        "Those traces should now be visible in the LangSmith UI, again under the same project:\n",
        "\n",
        "![LangSmith Traces](https://github.com/aurelio-labs/langchain-course/blob/main/assets/langsmith-ui-02.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvuze3LTqCQl"
      },
      "source": [
        "We can various metrics here for each run. First, ofcourse, the run name. We can see any inputs and outputs from each run, we can see if the run raised any errors, it's start time, and latency. Inside the UI we can also filter for specific runs, like so:\n",
        "\n",
        "![LangSmith UI filters](https://github.com/aurelio-labs/langchain-course/blob/main/assets/langsmith-ui-03.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7UR0DPwqCQl"
      },
      "source": [
        "There are various other things we can do within the UI, but we'll leave that for you to explore.\n",
        "\n",
        "Finally, we can also modify our traceable names if we'd like to make them more readable inside the UI. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dQLkwo0PqCQl"
      },
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "@traceable(name=\"Chitchat Maker\")\n",
        "def error_generation_function(question: str):\n",
        "    delay = random.randint(0, 3)\n",
        "    time.sleep(delay)\n",
        "    number = random.randint(0, 1)\n",
        "    if number == 0:\n",
        "        raise ValueError(\"Random error\")\n",
        "    else:\n",
        "        return \"I'm great how are you?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8NFR6qqCQl"
      },
      "source": [
        "Let's run this a few times and see what we get in LangSmith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e988534598c54261a671bc9e17fdb81b",
            "4c3b5008fb254259bfded2cffaa43790",
            "5e63efa23bd54da5bc94a6776f11d0e7",
            "15c2401e19a34ce48286460dad8bf4b2",
            "c884ebe0266b47aa9620600ed2169c81",
            "a27c7c05a70041fcb8dfab45692ef7fc",
            "c1bc2c068ee840d38a4b615f108e4e0c",
            "ffce1b8c4b8646c2b00f81058cb6e6c0",
            "786d6b07a8104f5fa499fbf345bc831f",
            "479c419c88a3443b8c39767fb3540c8b",
            "290f779d73ca42c9bd826518d686bbea"
          ]
        },
        "id": "ay8sxvXWqCQm",
        "outputId": "bafa13da-6ffe-48cb-fa5c-4e18e65a6e3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n"
          ]
        }
      ],
      "source": [
        "for _ in tqdm(range(10)):\n",
        "    try:\n",
        "        error_generation_function(\"How are you today?\")\n",
        "    except ValueError:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsITHuXBqCQm"
      },
      "source": [
        "Let's filter for the `Chitchat Maker` traceable and see our results.\n",
        "\n",
        "![LangSmith Chitchat Maker runs](https://github.com/aurelio-labs/langchain-course/blob/main/assets/langsmith-ui-04.jpg?raw=1)\n",
        "\n",
        "We can see our runs and their related metadata! That's it for this intro to LangSmith. As we work through the course we will (optionally) refer to LangSmith for digging into our runs."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
